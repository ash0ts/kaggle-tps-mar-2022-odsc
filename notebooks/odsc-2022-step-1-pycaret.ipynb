{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"odsc-2022-step-1-pycaret.ipynb","provenance":[],"collapsed_sections":["7mnOFtqFuqaG"],"authorship_tag":"ABX9TyPRPGQfE3IzsGnlwwWJ4sHH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1IHfKKWBjqxuMLAFAP_QjcJ2lfEyYYI9V?usp=sharing)"],"metadata":{"id":"biiGjWUYjTox"}},{"cell_type":"markdown","source":["## Colab Setup"],"metadata":{"id":"7mnOFtqFuqaG"}},{"cell_type":"code","source":["try:\n","    import google.colab\n","    IN_COLAB = True\n","except:\n","    IN_COLAB = False"],"metadata":{"id":"dgWZs63FMF6T","executionInfo":{"status":"ok","timestamp":1650493148361,"user_tz":240,"elapsed":173,"user":{"displayName":"Anish Shah","userId":"05913492621931233323"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["%%capture\n","if IN_COLAB:\n","    \n","    #Remove not needed python versions to free space\n","    !rm -rf \"/usr/local/lib/python2.7\"\n","    !rm -rf \"/usr/lib/python2.7\"\n","\n","    # Clone the repo.\n","    # !git clone \"\"\n","\n","    # Change the working directory to the repo root.\n","    # %cd\n","\n","    # Add the repo root to the Python path.\n","    # import sys, os\n","    # sys.path.append(os.getcwd())\n","    \n","    #Install packages not native to colab\n","    !pip install python-dotenv\n","    !pip install pycaret\n","\n","    #Mount GDrive to access .env file\n","    from google.colab import drive\n","    drive.mount('/content/gdrive')\n","\n","    #Load env file\n","    #NOTE: gdrive wont allow you to mount dotfiles\n","    from dotenv import load_dotenv\n","    load_dotenv(\"./gdrive/MyDrive/ODSC 2022/my_env_file\")"],"metadata":{"id":"8XRGNtsTMFNJ","executionInfo":{"status":"ok","timestamp":1650493248200,"user_tz":240,"elapsed":99695,"user":{"displayName":"Anish Shah","userId":"05913492621931233323"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["## 1. Pull Data"],"metadata":{"id":"Fjy2h9ixuvfQ"}},{"cell_type":"code","source":["from kaggle.api.kaggle_api_extended import KaggleApi\n","import os\n","from zipfile import ZipFile"],"metadata":{"id":"aEuLmaJdPkFt","executionInfo":{"status":"ok","timestamp":1650493255691,"user_tz":240,"elapsed":508,"user":{"displayName":"Anish Shah","userId":"05913492621931233323"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def download_kaggle_data(competition: str = \"tabular-playground-series-mar-2022\"):\n","\n","    api = KaggleApi()\n","    api.authenticate()\n","    api.competition_download_files(competition)\n","    zip_path = f\"{competition}.zip\"\n","    path_to_raw = os.path.join(\".\", \"data\", \"raw\")\n","    ZipFile(zip_path).extractall(path=path_to_raw)\n","    os.remove(zip_path)\n","\n","    return path_to_raw"],"metadata":{"id":"yVXADTHSPzHb","executionInfo":{"status":"ok","timestamp":1650493255693,"user_tz":240,"elapsed":7,"user":{"displayName":"Anish Shah","userId":"05913492621931233323"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["## 2. Feature Engineer"],"metadata":{"id":"APrPIFSMux6v"}},{"cell_type":"code","source":["import pandas as pd"],"metadata":{"id":"QWyBDo-PQeV1","executionInfo":{"status":"ok","timestamp":1650493257882,"user_tz":240,"elapsed":1511,"user":{"displayName":"Anish Shah","userId":"05913492621931233323"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def feature_engineer(data):\n","    \n","    \n","    data['time'] = pd.to_datetime(data['time'])\n","    data['month'] = data['time'].dt.month\n","    data['weekday'] = data['time'].dt.weekday\n","    data['hour'] = data['time'].dt.hour\n","    data['minute'] = data['time'].dt.minute\n","    data['is_month_start'] = data['time'].dt.is_month_start.astype('int')\n","    data['is_month_end'] = data['time'].dt.is_month_end.astype('int')\n","    data['hour+minute'] = data['time'].dt.hour * 60 + data['time'].dt.minute\n","    data['is_weekend'] = (data['time'].dt.dayofweek > 4).astype('int')\n","    data['is_afternoon'] = (data['time'].dt.hour > 12).astype('int')\n","    data['x+y'] = data['x'].astype('str') + data['y'].astype('str')\n","    data['x+y+direction'] = data['x'].astype('str') + data['y'].astype('str') + data['direction'].astype('str')\n","    data['hour+direction'] = data['hour'].astype('str') + data['direction'].astype('str')\n","    data['hour+x+y'] = data['hour'].astype('str') + data['x'].astype('str') + data['y'].astype('str')\n","    data['hour+direction+x'] = data['hour'].astype('str') + data['direction'].astype('str') + data['x'].astype('str')\n","    data['hour+direction+y'] = data['hour'].astype('str') + data['direction'].astype('str') + data['y'].astype('str')\n","    data['hour+direction+x+y'] = data['hour'].astype('str') + data['direction'].astype('str') + data['x'].astype('str') + data['y'].astype('str')\n","    data['hour+x'] = data['hour'].astype('str') + data['x'].astype('str')\n","    data['hour+y'] = data['hour'].astype('str') + data['y'].astype('str')\n","    return data"],"metadata":{"id":"imR0PFUKP_op","executionInfo":{"status":"ok","timestamp":1650493257884,"user_tz":240,"elapsed":7,"user":{"displayName":"Anish Shah","userId":"05913492621931233323"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def feature_engineer_tps_2022(comp_data_path: str):\n","    \n","    train_path = os.path.join(comp_data_path, \"train.csv\")\n","    test_path = os.path.join(comp_data_path, \"test.csv\")\n","    submission_path = os.path.join(comp_data_path, \"sample_submission.csv\")\n","    \n","    train_data = pd.read_csv(train_path, dtype={'time': str})\n","    test_data = pd.read_csv(test_path, dtype={'time': str})\n","    submission = pd.read_csv(submission_path)\n","\n","    fe_train_data = feature_engineer(train_data)\n","    fe_test_data = feature_engineer(test_data)\n","    \n","    return fe_train_data, fe_test_data, submission"],"metadata":{"id":"dUtMLSg1QGsI","executionInfo":{"status":"ok","timestamp":1650493258072,"user_tz":240,"elapsed":3,"user":{"displayName":"Anish Shah","userId":"05913492621931233323"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["## 3. Model"],"metadata":{"id":"jA-E4s1Ou4I1"}},{"cell_type":"code","source":["from pycaret.regression import *"],"metadata":{"id":"9cUbMjlLnKlj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650493266373,"user_tz":240,"elapsed":7243,"user":{"displayName":"Anish Shah","userId":"05913492621931233323"}},"outputId":"179ef5ba-202b-4ef1-bd48-befc4bcbe43a"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n","  defaults = yaml.load(f)\n"]}]},{"cell_type":"code","source":["# Accessory function to call the collection of functions needed to convert useful information from the pycaret run into loggable artifacts for lineaging\n","def perform_experiment(exp):\n","\n","    # Experiments are run by splitting a data into training and holdout internally, allowing their ability to make comparison\n","\n","    # Runs an experiment which will compare different model types here and select the best model type\n","    best_model = compare_models()\n","\n","    # Return the dataframe that shows the different metrics calculated for each of the tested model types\n","    leaderboard = get_leaderboard()\n","    # Get the internal names of the models for referential ID's in a DataFrame\n","    available_model_types = models()\n","    # Merge the above Dataframes\n","    model_comparison_results = leaderboard.reset_index().merge(available_model_types.reset_index(), left_on=\"Model Name\", right_on=\"Name\")\n","    return model_comparison_results, best_model"],"metadata":{"id":"ky1JSf-6SqB6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#https://pycaret.readthedocs.io/en/latest/api/regression.html\n","#TODO: Hardcode the relationships between the features and the numeric vs categorical features\n","def setup_tps_2022_config(seed):\n","    config = {\n","        \"target\": \"congestion\",\n","        \"fold_strategy\" : 'timeseries',\n","        \"session_id\": seed,\n","        \"ignore_features\" : [\"row_id\"],\n","#         \"transform_target\": True,\n","        \"experiment_name\": f\"tps_march_2022_{seed}\",\n","        \"silent\": True,\n","#         \"normalize\": True,\n","#         \"transformation\": True,\n","        \"ignore_low_variance\": True,\n","        \"remove_multicollinearity\": True,\n","        \"multicollinearity_threshold\": 0.95,\n","        # \"use_gpu\": True,\n","    }\n","    return config"],"metadata":{"id":"RRTThPPCSxNM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random"],"metadata":{"id":"U8Hsk3Q5nUUQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_tps_mar_2022_automl_model(all_train_data: pd.DataFrame, \n","                                    n: int = 2,\n","                                    sample = None): \n","    model_runs = []\n","    for i in range(n):\n","        #Use seed to create a unique configuration for the current pycaret experiment\n","        seed = i + 1 + random.randint(0, 1000)\n","\n","        config = setup_tps_2022_config(seed) #Your specific configs for pycaret data preparation\n","\n","        print(f\"Seed: {seed}\")\n","        \n","        #Hard coded because broken\n","        #Forcing small sample to train fast\n","        train_data = all_train_data[[\"row_id\", \"time\", \"congestion\", \"x\", \"y\", \"direction\"]]\n","        if sample:\n","            train_data = train_data.sample(sample, random_state=seed)\n","        train_data['time'] = pd.to_datetime(train_data['time'])\n","\n","        print(train_data.shape)\n","\n","        #setup and run experiment\n","        #TODO: run with the proper generated features\n","        ts_exp = setup(data=train_data, **config)\n","        model_comparison_results, best_model = perform_experiment(ts_exp)\n","\n","        model_runs.append(\n","            {\"seed\": seed, \n","             \"config\": config, \n","             \"run_results\": {\n","                 \"model_comparison_results\": model_comparison_results,\n","                 \"best_model\": best_model\n","                 }\n","            }\n","        )\n","    print(model_runs)\n","\n","    return model_runs"],"metadata":{"id":"4SUmiXhcS3oq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4. Promote Best Model"],"metadata":{"id":"wbiiwJjPu6gp"}},{"cell_type":"code","source":["from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error"],"metadata":{"id":"iqlVKKJVvt4g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# by=\"R2\"\n","def select_best_model(model_runs: dict, by: str = \"R2\"):\n","    best_model = None\n","    best_score = -1000000\n","    for model_run in model_runs:\n","        model_comparison_table = model_run[\"run_results\"][\"model_comparison_results\"]\n","        candidate_score = round(model_comparison_table.sort_values(by=by, ascending=False).iloc[0][by], 3)\n","        if candidate_score > best_score:\n","            best_score = candidate_score\n","            best_model = model_run[\"run_results\"][\"best_model\"]\n","    return best_model"],"metadata":{"id":"ql7q0zz005NB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 5. Evaluate"],"metadata":{"id":"c6G3zIN2vAIY"}},{"cell_type":"code","source":["# test_data = fe_test_data\n","# validate_by = sample_submission\n","\n","def predict_on_test_data(best_model, test_data: pd.DataFrame, validate_by = None):\n","    test_results = test_data.copy(deep=True)\n","    test_results['time'] = pd.to_datetime(test_results['time'])\n","    test_results[\"congestion\"] = 0\n","    unseen_df = test_results[[\"row_id\", \"time\", \"congestion\", \"x\", \"y\", \"direction\"]]\n","    test_results[\"prediction\"] = predict_model(best_model, data = unseen_df).rename({\"Label\": \"prediction\"}, axis=1)[\"prediction\"]\n","\n","    submission = test_results[[\"row_id\", \"prediction\"]].rename({\"prediction\": \"congestion\"}, axis=1)\n","    if validate_by.any(axis=None) != None:\n","        val_cols = validate_by.columns\n","        sub_cols = submission.columns\n","        if len(val_cols) == len(sub_cols):\n","            for i in range(len(val_cols)):\n","                val_cols[i] == sub_cols[i]\n","        else:\n","            raise ValueError(\"Too many columns in submission\")\n","    return submission"],"metadata":{"id":"Coqne-LssQgq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Run Pipeline"],"metadata":{"id":"5aeMDRsNvDbM"}},{"cell_type":"code","source":["# def e2e_tps_2022():\n","path_to_raw = download_kaggle_data()\n","fe_train_data, fe_test_data, sample_submission = feature_engineer_tps_2022(path_to_raw)\n","model_runs = train_tps_mar_2022_automl_model(fe_train_data, n=3, sample=1000)\n","best_model = select_best_model(model_runs, by=\"R2\")\n","submission = predict_on_test_data(best_model, fe_test_data, validate_by=sample_submission)\n","\n","# return submission"],"metadata":{"id":"7hHcRtQQXyaB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["submission"],"metadata":{"id":"dGwg_Jj731nt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"uaVMLU3A-fXQ"},"execution_count":null,"outputs":[]}]}
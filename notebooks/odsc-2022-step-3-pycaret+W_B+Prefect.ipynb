{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"odsc-2022-step-3-pycaret+W&B+Prefect.ipynb","provenance":[],"collapsed_sections":["m7f5qyShvv4e"],"authorship_tag":"ABX9TyPQ8OOg/oAWUN9BaHzqN+23"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/14obfKc7xpyAfngQywnSJUKVnmu1avdfr?usp=sharing)"],"metadata":{"id":"8rBu9q_6jnh5"}},{"cell_type":"markdown","source":["## Colab Setup"],"metadata":{"id":"m7f5qyShvv4e"}},{"cell_type":"code","source":["try:\n","    import google.colab\n","    IN_COLAB = True\n","except:\n","    IN_COLAB = False"],"metadata":{"id":"dgWZs63FMF6T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%capture\n","if IN_COLAB:\n","    \n","    #Remove not needed python versions to free space\n","    !rm -rf \"/usr/local/lib/python2.7\"\n","    !rm -rf \"/usr/lib/python2.7\"\n","\n","    # Clone the repo.\n","    # !git clone \"\"\n","\n","    # Change the working directory to the repo root.\n","    # %cd\n","\n","    # Add the repo root to the Python path.\n","    # import sys, os\n","    # sys.path.append(os.getcwd())\n","    \n","    #Install packages not native to colab\n","    !pip install python-dotenv\n","    !pip install pycaret\n","    !pip install wandb\n","    !pip install shap\n","    !pip install prefect\n","\n","    #Mount GDrive to access .env file\n","    from google.colab import drive\n","    drive.mount('/content/gdrive')\n","\n","    #Load env file\n","    #NOTE: gdrive wont allow you to mount dotfiles\n","    from dotenv import load_dotenv\n","    load_dotenv(\"./gdrive/MyDrive/ODSC 2022/my_env_file\")"],"metadata":{"id":"8XRGNtsTMFNJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Accessory function for WANDB"],"metadata":{"id":"Q-eJG59Avxi3"}},{"cell_type":"code","source":["import wandb\n","from pandas_profiling import ProfileReport"],"metadata":{"id":"4LEKss5qCobx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def add_convert_for_wandb(artifact, path, profile=True, sample=2500):\n","    \n","    artifact.add_dir(path, name=\"data\")\n","\n","    for file_name in os.listdir(path):\n","        if file_name.endswith(\".csv\"):\n","            path_to_file = os.path.join(path, file_name)\n","            tab_name = file_name.replace(\".csv\", \"\")\n","            print(f\"adding {tab_name}\")\n","            df = pd.read_csv(path_to_file)\n","            print(f\"{tab_name}:{df.shape}\")\n","\n","            if df.shape[0] < sample:\n","                sampled_df = df\n","            else:\n","                sampled_df = df.sample(sample)\n","\n","            table = wandb.Table(dataframe=sampled_df)\n","            artifact.add(table, name=tab_name)\n","            \n","            if profile:\n","                #The output of the profile report will be an HTML which we will log to W&B under the artifact made\n","                data_profile = ProfileReport(df, dark_mode=True, title=tab_name, minimal=True)\n","                profile_path = f\"{tab_name}.html\"\n","                data_profile.to_file(profile_path)\n","                data_table_profile = wandb.Html(profile_path)\n","                artifact.add(data_table_profile, f\"{tab_name}_profile\")\n","                # artifact.add_file(profile_path)\n","                \n","    return None"],"metadata":{"id":"QSBLNeGWCjJ5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Import Prefect"],"metadata":{"id":"9xHzPkgKv-dh"}},{"cell_type":"code","source":["import prefect\n","from prefect import task, Flow, Parameter\n","from prefect.run_configs import LocalRun\n","from prefect.storage import Local #TODO: make this work with local device"],"metadata":{"id":"V1VAMDhjp0wC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 1. Pull Data"],"metadata":{"id":"V3kpMiVkv68U"}},{"cell_type":"code","source":["from kaggle.api.kaggle_api_extended import KaggleApi\n","import os\n","from zipfile import ZipFile"],"metadata":{"id":"aEuLmaJdPkFt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["@task(log_stdout=True)\n","def download_kaggle_data(competition: str = \"tabular-playground-series-mar-2022\", project_name: str = \"kaggle-tps-mar-2022-odsc\", **kwargs):\n","\n","    print(f\"starting new run for {project_name}\")\n","    run = wandb.init(\n","        project=project_name, job_type=\"download\", name=f\"log-{competition}\")\n","\n","    api = KaggleApi()\n","    api.authenticate()\n","    api.competition_download_files(competition)\n","    zip_path = f\"{competition}.zip\"\n","    path_to_raw = os.path.join(\".\", \"data\", \"raw\")\n","    ZipFile(zip_path).extractall(path=path_to_raw)\n","    os.remove(zip_path)\n","\n","    # TODO: Remove hack to add data secription\n","    if competition == \"tabular-playground-series-mar-2022\":\n","        data_description = \"\"\"\n","            In this competition, you'll forecast twelve-hours of traffic flow in a major U.S. metropolitan area. Time, space, and directional features give you the chance to model interactions across a network of roadways.\n","\n","            Files and Field Descriptions\n","            -------------------------------\n","            train.csv - the training set, comprising measurements of traffic congestion across 65 roadways from April through September of 1991.\n","            row_id - a unique identifier for this instance\n","            time - the 20-minute period in which each measurement was taken\n","            x - the east-west midpoint coordinate of the roadway\n","            y - the north-south midpoint coordinate of the roadway\n","            direction - the direction of travel of the roadway. EB indicates \"eastbound\" travel, for example, while SW indicates a \"southwest\" direction of travel.\n","            congestion - congestion levels for the roadway during each hour; the target. The congestion measurements have been normalized to the range 0 to 100.\n","            test.csv - the test set; you will make hourly predictions for roadways identified by a coordinate location and a direction of travel on the day of 1991-09-30.\n","            sample_submission.csv - a sample submission file in the correct format\n","        \"\"\"\n","\n","    raw_data_artifact = wandb.Artifact(\n","        name=\"raw\", type=competition, description=data_description)\n","    add_convert_for_wandb(raw_data_artifact, path_to_raw)\n","\n","    run.log_artifact(raw_data_artifact)\n","    run.finish()\n","\n","    return None"],"metadata":{"id":"yVXADTHSPzHb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2. Feature Engineer"],"metadata":{"id":"lZhA29P5wB0g"}},{"cell_type":"code","source":["import pandas as pd"],"metadata":{"id":"QWyBDo-PQeV1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def feature_engineer(data):\n","    \n","    \n","    data['time'] = pd.to_datetime(data['time'])\n","    data['month'] = data['time'].dt.month\n","    data['weekday'] = data['time'].dt.weekday\n","    data['hour'] = data['time'].dt.hour\n","    data['minute'] = data['time'].dt.minute\n","    data['is_month_start'] = data['time'].dt.is_month_start.astype('int')\n","    data['is_month_end'] = data['time'].dt.is_month_end.astype('int')\n","    data['hour+minute'] = data['time'].dt.hour * 60 + data['time'].dt.minute\n","    data['is_weekend'] = (data['time'].dt.dayofweek > 4).astype('int')\n","    data['is_afternoon'] = (data['time'].dt.hour > 12).astype('int')\n","    data['x+y'] = data['x'].astype('str') + data['y'].astype('str')\n","    data['x+y+direction'] = data['x'].astype('str') + data['y'].astype('str') + data['direction'].astype('str')\n","    data['hour+direction'] = data['hour'].astype('str') + data['direction'].astype('str')\n","    data['hour+x+y'] = data['hour'].astype('str') + data['x'].astype('str') + data['y'].astype('str')\n","    data['hour+direction+x'] = data['hour'].astype('str') + data['direction'].astype('str') + data['x'].astype('str')\n","    data['hour+direction+y'] = data['hour'].astype('str') + data['direction'].astype('str') + data['y'].astype('str')\n","    data['hour+direction+x+y'] = data['hour'].astype('str') + data['direction'].astype('str') + data['x'].astype('str') + data['y'].astype('str')\n","    data['hour+x'] = data['hour'].astype('str') + data['x'].astype('str')\n","    data['hour+y'] = data['hour'].astype('str') + data['y'].astype('str')\n","    return data"],"metadata":{"id":"imR0PFUKP_op"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["@task(log_stdout=True)\n","def feature_engineer_tps_2022(competition: str = \"tabular-playground-series-mar-2022\", project_name: str = \"kaggle-tps-mar-2022-odsc\", **kwargs):\n","    run = wandb.init(\n","        project=project_name, job_type=\"feature_engineer\", name=f\"feature_engineer-{competition}\")\n","    comp_data_art = run.use_artifact(f\"{project_name}/raw:latest\", type=competition)\n","    comp_data_path = os.path.join(comp_data_art.download(), \"data\")\n","\n","    train_path = os.path.join(comp_data_path, \"train.csv\")\n","    test_path = os.path.join(comp_data_path, \"test.csv\")\n","    submission_path = os.path.join(comp_data_path, \"sample_submission.csv\")\n","    \n","    train_data = pd.read_csv(train_path, dtype={'time': str})\n","    test_data = pd.read_csv(test_path, dtype={'time': str})\n","    submission = pd.read_csv(submission_path)\n","\n","    fe_train_data = feature_engineer(train_data)\n","    fe_test_data = feature_engineer(test_data)\n","\n","    local_data_dir = os.path.join(\".\", \"data\")\n","    fe_path = os.path.join(local_data_dir, \"fe\")\n","    if not os.path.exists(fe_path):\n","        os.makedirs(fe_path)\n","    \n","    fe_train_data_path = os.path.join(fe_path, \"fe_train.csv\")\n","    fe_test_data_path = os.path.join(fe_path, \"fe_test.csv\")\n","    \n","    fe_train_data.to_csv(fe_train_data_path, index=False)\n","    fe_test_data.to_csv(fe_test_data_path, index=False)\n","    \n","    fe_artifact = wandb.Artifact(\n","        name=\"feature_engineered\", type=competition)\n","    add_convert_for_wandb(fe_artifact, fe_path)\n","    \n","    run.log_artifact(fe_artifact)\n","    run.finish()\n","    \n","    return None"],"metadata":{"id":"dUtMLSg1QGsI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3. Model"],"metadata":{"id":"hPP5_ULPwEiT"}},{"cell_type":"code","source":["from pycaret.regression import *"],"metadata":{"id":"9cUbMjlLnKlj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Accessory function to call the collection of functions needed to convert useful information from the pycaret run into loggable artifacts for lineaging\n","def perform_experiment(exp):\n","\n","    # Experiments are run by splitting a data into training and holdout internally, allowing their ability to make comparison\n","\n","    # Runs an experiment which will compare different model types here and select the best model type\n","    best_model = compare_models()\n","\n","    # Return the dataframe that shows the different metrics calculated for each of the tested model types\n","    leaderboard = get_leaderboard()\n","    # Get the internal names of the models for referential ID's in a DataFrame\n","    available_model_types = models()\n","    # Merge the above Dataframes\n","    model_comparison_results = leaderboard.reset_index().merge(available_model_types.reset_index(), left_on=\"Model Name\", right_on=\"Name\")\n","    return model_comparison_results, best_model"],"metadata":{"id":"ky1JSf-6SqB6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#https://pycaret.readthedocs.io/en/latest/api/regression.html\n","#TODO: Hardcode the relationships between the features and the numeric vs categorical features\n","def setup_tps_2022_config(seed):\n","    config = {\n","        \"target\": \"congestion\",\n","        \"fold_strategy\" : 'timeseries',\n","        \"session_id\": seed,\n","        \"ignore_features\" : [\"row_id\"],\n","        \"log_experiment\": \"wandb\",\n","#         \"transform_target\": True,\n","        \"experiment_name\": f\"tps_march_2022_{seed}\",\n","        \"silent\": True,\n","#         \"normalize\": True,\n","#         \"transformation\": True,\n","        \"ignore_low_variance\": True,\n","        \"remove_multicollinearity\": True,\n","        \"multicollinearity_threshold\": 0.95,\n","        # \"use_gpu\": True,\n","    }\n","    return config"],"metadata":{"id":"RRTThPPCSxNM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random"],"metadata":{"id":"U8Hsk3Q5nUUQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["@task(log_stdout=True)\n","def train_tps_mar_2022_automl_model(competition: str = \"tabular-playground-series-mar-2022\", \n","                                    project_name: str = \"kaggle-tps-mar-2022-odsc\", \n","                                    n: int = 2,\n","                                    sample = None, **kwargs): \n","    print(n)\n","    print(sample)\n","    \n","    for i in range(n):\n","        #Use seed to create a unique configuration for the current pycaret experiment\n","        seed = i + 1 + random.randint(0, 1000)\n","\n","        config = setup_tps_2022_config(seed) #Your specific configs for pycaret data preparation\n","\n","        #Initialize wandb run to begin logging for pycaret experiment\n","        run = wandb.init(project=project_name, reinit=True, config = config, job_type=\"train\",\n","                   name=f\"train-seed-{seed}-{competition}\")\n","        print(f\"Seed: {seed}\")\n","\n","        #Pull latest training data from wandb and load into df\n","        fe_data_art = run.use_artifact(f\"{project_name}/feature_engineered:latest\", type=competition)\n","        train_data_path = fe_data_art.get_path(\"data/fe_train.csv\").download()\n","        \n","        all_train_data = pd.read_csv(train_data_path)#.convert_dtypes()\n","        \n","        #Hard coded because broken\n","        #Forcing small sample to train fast\n","        #TODO: Add this as an input parameter\n","        train_data = all_train_data[[\"row_id\", \"time\", \"congestion\", \"x\", \"y\", \"direction\"]]\n","        if sample:\n","            train_data = train_data.sample(sample, random_state=seed)\n","        train_data['time'] = pd.to_datetime(train_data['time'])\n","\n","        print(train_data.shape)\n","\n","        #setup and run experiment\n","        #TODO: run with the proper generated features\n","        ts_exp = setup(data=train_data, **config)\n","        model_comparison_results, best_model = perform_experiment(ts_exp)\n","\n","        # save model\n","        model_title = f\"{competition}-{seed}\"\n","        save_model(best_model, model_title)\n","        \n","        interpret_model(best_model, save=True)\n","        \n","        # generate wandb tables from the results dfs from our experiment\n","        model_artifacts = wandb.Artifact(\"model_artifacts\", type=competition)\n","\n","        # add all objects to artifact\n","        model_artifacts.add_file(f\"{model_title}.pkl\", name=\"model.pkl\")\n","        #TODO: log this to run as opposed to artifact\n","        model_artifacts.add_file(\"SHAP summary.png\")\n","\n","        run.log_artifact(model_artifacts)\n","\n","        run.finish()\n","\n","    return None"],"metadata":{"id":"4SUmiXhcS3oq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4. Promote Best Model"],"metadata":{"id":"qZCCEuIdwJXp"}},{"cell_type":"code","source":["# by=\"R2\"\n","# project_name = \"kaggle-tps-mar-2022-odsc\"\n","@task(log_stdout=True)\n","def select_best_model(competition: str = \"tabular-playground-series-mar-2022\", project_name: str = \"kaggle-tps-mar-2022-odsc\", by: str = \"R2\", **kwargs):\n","    print(by)\n","    \n","    api = wandb.Api({\"project\": project_name})\n","    train_runs = api.runs(filters={\"jobType\": \"train\"})\n","\n","    best_run = None\n","    best_model = None\n","    best_score = -1000000\n","\n","    run = wandb.init(project=project_name, job_type=\"promote\",\n","                    name=f\"promote_best_model\")\n","    for train_run in train_runs:\n","        model_comparison_table = run.use_artifact(f\"run-{train_run.id}-compare_models:latest\")[\"compare_models\"]\n","        model_comparison_df = pd.DataFrame(data = model_comparison_table.data, columns=model_comparison_table.columns)\n","        candidate_score = round(model_comparison_df.sort_values(by=by, ascending=False).iloc[0][by], 3)\n","        if candidate_score > best_score:\n","            best_score = candidate_score\n","            best_run = train_run\n","\n","    for artifact in best_run.logged_artifacts():\n","        if artifact.name.startswith(\"model_artifacts\"):\n","            best_model = run.use_artifact(artifact.name)\n","            best_model.aliases.append(\"production\")\n","            best_model.save()\n","\n","    run.finish()\n","\n","    return None"],"metadata":{"id":"a5t3HgnFIq9T"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 5. Evaluate"],"metadata":{"id":"xodkRJbSwMM0"}},{"cell_type":"code","source":["# project_name = \"kaggle-tps-mar-2022-odsc\"\n","# competition = \"tabular-playground-series-mar-2022\"\n","@task(log_stdout=True)\n","def predict_on_test_data(competition : str = \"tabular-playground-series-mar-2022\", project_name : str = \"kaggle-tps-mar-2022-odsc\", **kwargs):\n","    run = wandb.init(project=project_name, job_type=\"evaluate\",\n","                        name=f\"evaluate_prod_model\")\n","\n","    fe_data_art = run.use_artifact(f\"{project_name}/feature_engineered:latest\", type=competition)\n","    test_data_path = fe_data_art.get_path(\"data/fe_test.csv\").download()\n","    test_data = pd.read_csv(test_data_path)\n","\n","    model_arts = run.use_artifact(\"model_artifacts:production\")\n","    best_model_path = model_arts.get_path(\"model.pkl\").download()\n","    best_model = load_model(best_model_path.replace(\".pkl\", \"\"))\n","\n","    comp_data_art = run.use_artifact(f\"{project_name}/raw:latest\", type=competition)\n","    sample_submission_path = comp_data_art.get_path(\"data/sample_submission.csv\").download()\n","    validate_by = pd.read_csv(sample_submission_path)\n","\n","    test_results = test_data.copy(deep=True)\n","    test_results['time'] = pd.to_datetime(test_results['time'])\n","    test_results[\"congestion\"] = 0\n","    unseen_df = test_results[[\"row_id\", \"time\", \"congestion\", \"x\", \"y\", \"direction\"]]\n","    test_results[\"prediction\"] = predict_model(best_model, data = unseen_df).rename({\"Label\": \"prediction\"}, axis=1)[\"prediction\"]\n","\n","    submission = test_results[[\"row_id\", \"prediction\"]].rename({\"prediction\": \"congestion\"}, axis=1)\n","    if validate_by.any(axis=None) != None:\n","        val_cols = validate_by.columns\n","        sub_cols = submission.columns\n","        if len(val_cols) == len(sub_cols):\n","            for i in range(len(val_cols)):\n","                val_cols[i] == sub_cols[i]\n","        else:\n","            raise ValueError(\"Too many columns in submission\")\n","\n","    local_data_dir = os.path.join(\".\", \"data\")\n","    submission_dir = os.path.join(local_data_dir, \"sub\")\n","    if not os.path.exists(submission_dir):\n","        os.makedirs(submission_dir)\n","\n","    submission.to_csv(os.path.join(submission_dir, \"submission.csv\"), index=False)\n","\n","    submission_artifact = wandb.Artifact(\"submission\", type=competition)\n","    add_convert_for_wandb(submission_artifact, submission_dir)\n","    \n","    run.log_artifact(submission_artifact)\n","    run.finish()\n","\n","    return None"],"metadata":{"id":"QMjvSxtOUxjS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Configure Pipeline"],"metadata":{"id":"VHlDDsSBwQt3"}},{"cell_type":"code","source":["def configure_prefect_flow():\n","\n","    with Flow(\"odsc-2022-step-3-pycaret-WB-Prefect\", storage=Local(add_default_labels=False)) as flow:\n","        competition = Parameter(\n","            \"competition\", default=\"tabular-playground-series-mar-2022\")\n","        project_name = Parameter(\n","            \"project_name\", default=\"kaggle-tps-mar-2022-odsc\")\n","        num_experiments = Parameter(\n","            \"n\", default=3)\n","        num_training_points = Parameter(\"sample\", default=1000)\n","        model_selection_metric = Parameter(\"by\", default=\"R2\")\n","\n","        download_success = download_kaggle_data(competition=competition, project_name=project_name)\n","        fe_success = feature_engineer_tps_2022(competition=competition, project_name=project_name, download_success=download_success)\n","        train_success = train_tps_mar_2022_automl_model(competition=competition, project_name=project_name, n=num_experiments, sample=num_training_points, fe_success=fe_success)\n","        promote_success = select_best_model(competition=competition, project_name=project_name, by=model_selection_metric, train_success=train_success)\n","        predict_success = predict_on_test_data(competition=competition, project_name=project_name, promote_success=promote_success)\n","\n","    # Configure the `PROJECT` environment variable for this flow\n","    flow.run_config = LocalRun(\n","        env={\"KAGGLE_USERNAME\": os.environ[\"KAGGLE_USERNAME\"],\n","             \"KAGGLE_KEY\": os.environ[\"KAGGLE_KEY\"], \"WANDB_API_KEY\": os.environ[\"WANDB_API_KEY\"]})\n","\n","    # return flow\n","    flow.register(project_name=\"odsc-east-2022\")\n","    # flow.run()"],"metadata":{"id":"ygnoMfy-rMLc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["flow = configure_prefect_flow()"],"metadata":{"id":"8CjVKsiGH_tT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Run Pipeline *started and orchestrated by Prefect*"],"metadata":{"id":"IdvuRN0iwUAv"}},{"cell_type":"code","source":["!prefect agent local start"],"metadata":{"id":"mtY6-TGWtq4J"},"execution_count":null,"outputs":[]}]}